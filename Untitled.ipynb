{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation on test set of car with model: checkpoints/car_m_01_1e5_n_8_b_128/200_model.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangxun/.local/lib/python2.7/site-packages/torchvision/transforms/transforms.py:156: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n",
      "/home/wangxun/.local/lib/python2.7/site-packages/torchvision/transforms/transforms.py:397: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\n",
      "  \"please use transforms.RandomResizedCrop instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract Features: [20/128]\tTime 1.033 (1.106)\tData 0.971 (0.929)\t\n",
      "Extract Features: [40/128]\tTime 0.612 (0.933)\tData 0.551 (0.813)\t\n",
      "Extract Features: [60/128]\tTime 1.939 (1.050)\tData 1.873 (0.949)\t\n",
      "Extract Features: [80/128]\tTime 0.746 (1.239)\tData 0.677 (1.147)\t\n",
      "Extract Features: [100/128]\tTime 1.372 (1.280)\tData 1.306 (1.193)\t\n",
      "Extract Features: [120/128]\tTime 1.646 (1.245)\tData 1.580 (1.161)\t\n",
      "[ 0.59943426  0.71676301  0.81810355  0.8867298 ]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# import argparse\n",
    "import torch.utils.data\n",
    "from torch.backends import cudnn\n",
    "from evaluations import Recall_at_ks, NMI\n",
    "from evaluations import extract_features, pairwise_similarity\n",
    "import DataSet\n",
    "# from utils import RandomIdentitySampler\n",
    "test = 1\n",
    "\n",
    "model_path = 'checkpoints/cub_m_01_1e5_n_8_b_128/400_model.pkl'\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# model = inception_v3(dropout=0.5)\n",
    "model = torch.load(model_path)\n",
    "model = model.cuda()\n",
    "data = 'cub'\n",
    "if test == 1:\n",
    "    print('evaluation on test set of %s with model: %s' %(data, model_path))\n",
    "    data = DataSet.create(data, train=False)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        data.test, batch_size=64, shuffle=False, drop_last=False)\n",
    "else:\n",
    "    print('evaluation on train set of %s with model: %s' %(data, model_path))\n",
    "    data = DataSet.create(data, test=False)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        data.train, batch_size=64, shuffle=False, drop_last=False)\n",
    "\n",
    "features, labels = extract_features(model, data_loader, print_freq=30, metric=None)\n",
    "print('embedding dimension is:', len(features[0]))\n",
    "num_class = len(set(labels))\n",
    "print('number of classes is :', num_class)\n",
    "print('compute the NMI index:', NMI(features, labels, n_cluster=num_class))\n",
    "\n",
    "# print(len(features))\n",
    "sim_mat = pairwise_similarity(features)\n",
    "print(Recall_at_ks(sim_mat, query_ids=labels, gallery_ids=labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}